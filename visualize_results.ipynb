{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the outputs of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "from operator import add\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data\n",
    "\n",
    "from models import *\n",
    "from metrics import *\n",
    "from utils import read_image, process_image\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import *\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preambles\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\"model\": \"Unet\",\n",
    "           \"data\": \"fives\",\n",
    "           \"loss_fn\": \"clDice\",\n",
    "           \"size\": (224, 224),\n",
    "           \"augments\": False,\n",
    "           \"data_path\": 'datasets/',\n",
    "           \"result_path\": 'results',\n",
    "           \"device\": \"cuda\",\n",
    "           \"learning_rate\": 0.001,\n",
    "           \"batch_size\": 16,\n",
    "           \"epochs\": 40,\n",
    "           \"num_workers\": 2,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "_, _, test_x, test_y = get_data(configs)\n",
    "# x_sub, y_sub = zip(*random.sample(list(zip(test_x, test_y)), 5))\n",
    "data, label = zip(*random.sample(list(zip(test_x, test_y)), 5))\n",
    "# print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pred(x, model):\n",
    "    with torch.no_grad():\n",
    "        \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "        pred_y = model.predict(x)\n",
    "\n",
    "        pred_y = pred_y[0].cpu().numpy()  # (1, 512, 512)\n",
    "        pred_y = np.squeeze(pred_y, axis=0)  # (512, 512)\n",
    "        pred_y = pred_y > 0.5\n",
    "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_predictions(x, model_name: str, model_constructor, loss_names):\n",
    "    \"\"\" Batch predictions for the loss\"\"\"\n",
    "    predictions = {}\n",
    "    for loss_fn in loss_names:\n",
    "        predictor_name = f\"{configs['result_path']}/{model_name}/{configs['data']}/No_Augmentation_{loss_fn}\"\n",
    "        model = model_constructor().to(device)\n",
    "        model.load_state_dict(torch.load(predictor_name, map_location=device))\n",
    "        prediction = return_pred(x, model)\n",
    "        predictions[loss_fn] = prediction\n",
    "\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(image, mask, predictions):\n",
    "\n",
    "    \"\"\" Visualization \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2+len(predictions), figsize=(10, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].title.set_text(f\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(mask_parse(mask))\n",
    "    axes[1].title.set_text(f\"Ground Truth\")\n",
    "    axes[1].axis(\"off\")\n",
    "    for i, (k, v) in enumerate(predictions.items()):\n",
    "        print\n",
    "        axes[i+2].imshow(mask_parse(predictions[k])*255, cmap=\"seismic\")\n",
    "        axes[i+2].title.set_text(f\"{k} Prediction\")\n",
    "        axes[i+2].axis(\"off\")\n",
    "    fig.show()\n",
    "    # # save image\n",
    "    # fig.savefig(f\"results/{data_str}/{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_predictions(model_name, model_constructor, data, label):\n",
    "    for i, (x, y) in enumerate(zip(data, label)):\n",
    "        \"\"\" Extract the name \"\"\"\n",
    "        # name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" read and process image \"\"\"\n",
    "        image, mask = read_image(x, y)\n",
    "        x, y = process_image(image, mask)\n",
    "        \"Get Bathc predictions for the loss\"\n",
    "        loss_names = [\"cldice\", \"DiceLoss\"]\n",
    "        \n",
    "        predictions = get_batch_predictions(x, model_name, model_constructor, loss_names)\n",
    "\n",
    "        visualize_sample(image, mask, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images predictions for UNET model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Unet\"\n",
    "model_constructor = Unet\n",
    "plot_image_predictions(model_name, model_constructor, data, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images predictions for FPN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FPN\"\n",
    "model_constructor = FPN\n",
    "plot_image_predictions(model_name, model_constructor, data, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images predictions for MANet model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MANet\"\n",
    "model_constructor = MANet\n",
    "plot_image_predictions(model_name, model_constructor, data, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images predictions for UNET++ model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Unet++\"\n",
    "model_constructor = UnetPlusPlus\n",
    "plot_image_predictions(model_name, model_constructor, data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images, preprocessed image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = 224\n",
    "W = 224\n",
    "size = (W, H)\n",
    "\n",
    "def read_image(file_name, size):\n",
    "\n",
    "    image = cv2.imread(file_name, cv2.IMREAD_COLOR) ## (512, 512, 3)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, size)\n",
    "\n",
    "    return image\n",
    "\n",
    "def process(image):\n",
    "    # x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n",
    "    x = image/255.0\n",
    "    # x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n",
    "    x = x.astype(np.float32)\n",
    "    # x = torch.from_numpy(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_processed_images(orig_path, proc_path, mask_path):\n",
    "\n",
    "    orig_image = read_image(orig_path, size)\n",
    "    proc_image = read_image(proc_path, size)\n",
    "    mask_image = read_image(mask_path, size)\n",
    "\n",
    "    x = process(orig_image)\n",
    "    x_ = process(proc_image)\n",
    "    y = process(mask_image)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Visualization \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=3, figsize=(12, 7))\n",
    "    axes[0].imshow(x)\n",
    "    axes[0].title.set_text(f\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(x_)\n",
    "    axes[1].title.set_text(f\"Processed Image\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(y)\n",
    "    axes[2].title.set_text(f\"Image Mask\")\n",
    "    axes[2].axis(\"off\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_path = 'datasets/UCH/4.jpg'\n",
    "proc_path = 'datasets/preprocessed_train/4.png'\n",
    "mask_path = 'datasets/masks_train/4.png'\n",
    "\n",
    "\n",
    "plot_processed_images(orig_path, proc_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_path = 'datasets/UCH/12.jpg'\n",
    "proc_path = 'datasets/preprocessed_train/12.png'\n",
    "mask_path = 'datasets/masks_train/12.png'\n",
    "\n",
    "\n",
    "plot_processed_images(orig_path, proc_path, mask_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8beec5578a1d30062fe655f4cf96dae1fcf82d547f4af52a2beb589dccc600e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
