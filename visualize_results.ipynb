{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the outputs of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "\n",
    "from operator import add\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import get_data\n",
    "from augmentaions import *\n",
    "from models import *\n",
    "from metrics import *\n",
    "from utils import read_image, process_image\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import *\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preambles\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"model\": model,\n",
    "          \"data\": data,\n",
    "          \"loss_fn\": loss,\n",
    "          \"size\": (224, 224),\n",
    "          \"augments\": False,\n",
    "          \"data_path\": '/mnt/qb/berens/users/jfadugba97/RetinaSegmentation/datasets/',\n",
    "          \"result_path\": '/mnt/qb/berens/users/jfadugba97/RetinaSegmentation/results',\n",
    "          \"device\": \"cuda\",\n",
    "          \"lr\": 0.0001,\n",
    "          \"batch_size\": 8,\n",
    "          \"epochs\": 50,\n",
    "          \"num_workers\": 2, \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "_, _, test_x, test_y = get_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_name = f\"{config['result_path']}/{config['model']}/{config['data']}/No_Augmentation_{config['loss_fn']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DeepLab, FPN, Unet]\n",
    "model_names = [\"DeepLab\", \"FPN\", \"Unet\"]\n",
    "# x_sub, y_sub = zip(*random.sample(list(zip(test_x, test_y)), 5))\n",
    "data, label = zip(*random.sample(list(zip(test_x, test_y)), 5))\n",
    "# print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pred(x, model):\n",
    "    with torch.no_grad():\n",
    "        \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "        pred_y = model.predict(x)\n",
    "\n",
    "        pred_y = pred_y[0].cpu().numpy()  # (1, 512, 512)\n",
    "        pred_y = np.squeeze(pred_y, axis=0)  # (512, 512)\n",
    "        pred_y = pred_y > 0.5\n",
    "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_predictions(x, model):\n",
    "    \"\"\" get predictions \"\"\"\n",
    "\n",
    "    predictions = {}\n",
    "    for (modelname, model_constructor) in zip(model_names, models):\n",
    "        try:\n",
    "            state_fname = f\"results/No_Augmentation_{modelname}-{data_str}\"\n",
    "            model = model_constructor().to(device)\n",
    "            model.load_state_dict(torch.load(state_fname, map_location=device))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{state_fname} not found, continuing...\")\n",
    "            continue\n",
    "        prediction = return_pred(x, model)\n",
    "        predictions[modelname] = prediction\n",
    "\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images predictions for different output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(zip(data, label)):\n",
    "\n",
    "    model_constructor = None\n",
    "    \"\"\" Extract the name \"\"\"\n",
    "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    \"\"\" read and process image \"\"\"\n",
    "    image, mask = read_image(x, y)\n",
    "    x, y = process_image(image, mask)\n",
    "    \"Get predictios\"\n",
    "    loss_names = [\"cldica\", \"Dice\"]\n",
    "    predictions = {}\n",
    "    for loss_name in loss_names:\n",
    "        predictor_name = f\"{config['result_path']}/{config['model']}/{config['data']}/No_Augmentation_{loss_name}\"\n",
    "        model = model_constructor().to(device)\n",
    "        model.load_state_dict(torch.load(predictor_name, map_location=device))\n",
    "        #call function to get prediction.\n",
    "        prediction = return_pred(x, model)\n",
    "        predictions[loss_name] = prediction\n",
    "    \n",
    "    \"\"\" Visualization \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2+len(predictions), figsize=(10, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].title.set_text(f\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(mask_parse(mask))\n",
    "    axes[1].title.set_text(f\"Ground Truth\")\n",
    "    axes[1].axis(\"off\")\n",
    "    for i, (k, v) in enumerate(predictions.items()):\n",
    "        print\n",
    "        axes[i+2].imshow(mask_parse(predictions[k])*255, cmap=\"seismic\")\n",
    "        axes[i+2].title.set_text(f\"{k} Prediction\")\n",
    "        axes[i+2].axis(\"off\")\n",
    "\n",
    "    # save image\n",
    "    fig.savefig(f\"results/{data_str}/{name}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, (x, y) in enumerate(zip(data, label)):\n",
    "\n",
    "    \"\"\" Extract the name \"\"\"\n",
    "    name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    \"\"\" read and process image \"\"\"\n",
    "    image, mask = read_image(x, y)\n",
    "    x, y = process_image(image, mask)\n",
    "\n",
    "    predictions = {}\n",
    "    for (modelname, model_constructor) in zip(model_names, models):\n",
    "        try:\n",
    "            state_fname = f\"results/No_Augmentation_{modelname}-{data_str}\"\n",
    "            model = model_constructor().to(device)\n",
    "            model.load_state_dict(torch.load(state_fname, map_location=device))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{state_fname} not found, continuing...\")\n",
    "            continue\n",
    "        prediction = return_pred(x, model)\n",
    "        predictions[modelname] = prediction\n",
    "\n",
    "    \"\"\" Visualization \"\"\"\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2+len(predictions), figsize=(10, 5))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].title.set_text(f\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(mask_parse(mask))\n",
    "    axes[1].title.set_text(f\"Ground Truth\")\n",
    "    axes[1].axis(\"off\")\n",
    "    for i, (k, v) in enumerate(predictions.items()):\n",
    "        print\n",
    "        axes[i+2].imshow(mask_parse(predictions[k])*255, cmap=\"seismic\")\n",
    "        axes[i+2].title.set_text(f\"{k} Prediction\")\n",
    "        axes[i+2].axis(\"off\")\n",
    "\n",
    "    # save image\n",
    "    fig.savefig(f\"results/{data_str}/{name}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('retina')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8beec5578a1d30062fe655f4cf96dae1fcf82d547f4af52a2beb589dccc600e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
